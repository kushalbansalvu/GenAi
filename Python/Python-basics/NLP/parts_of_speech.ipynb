{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"In the early days of humanity, people lived simple lives, constantly striving for food, shelter, and safety. However, as time passed, they began to build civilizations, develop languages, and create complex societies. Though their environments changed and they faced challenges, the desire to grow and understand the world around them was always present. Many great thinkers and leaders emerged throughout history, guiding their nations towards progress, innovation, and knowledge. Still, despite the advancements in science, technology, and culture, humanity continues to face obstacles that test their resilience. It is essential, however, to remember that every step forward is a victory, and with each challenge, we grow stronger, wiser, and more connected.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text)\n",
    "print(type(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN'), ('early', 'JJ'), ('days', 'NNS'), ('humanity', 'NN'), (',', ','), ('people', 'NNS'), ('lived', 'VBD'), ('simple', 'JJ'), ('lives', 'NNS'), (',', ','), ('constantly', 'RB'), ('striving', 'VBG'), ('food', 'NN'), (',', ','), ('shelter', 'NN'), (',', ','), ('safety', 'NN'), ('.', '.')]\n",
      "[('However', 'RB'), (',', ','), ('time', 'NN'), ('passed', 'VBN'), (',', ','), ('began', 'VBD'), ('build', 'JJ'), ('civilizations', 'NNS'), (',', ','), ('develop', 'VB'), ('languages', 'NNS'), (',', ','), ('create', 'NN'), ('complex', 'JJ'), ('societies', 'NNS'), ('.', '.')]\n",
      "[('Though', 'IN'), ('environments', 'NNS'), ('changed', 'VBD'), ('faced', 'JJ'), ('challenges', 'NNS'), (',', ','), ('desire', 'NN'), ('grow', 'NN'), ('understand', 'VBP'), ('world', 'NN'), ('around', 'RP'), ('always', 'RB'), ('present', 'JJ'), ('.', '.')]\n",
      "[('Many', 'JJ'), ('great', 'JJ'), ('thinkers', 'NNS'), ('leaders', 'NNS'), ('emerged', 'VBD'), ('throughout', 'IN'), ('history', 'NN'), (',', ','), ('guiding', 'VBG'), ('nations', 'NNS'), ('towards', 'NNS'), ('progress', 'NN'), (',', ','), ('innovation', 'NN'), (',', ','), ('knowledge', 'NN'), ('.', '.')]\n",
      "[('Still', 'RB'), (',', ','), ('despite', 'IN'), ('advancements', 'NNS'), ('science', 'NN'), (',', ','), ('technology', 'NN'), (',', ','), ('culture', 'NN'), (',', ','), ('humanity', 'NN'), ('continues', 'VBZ'), ('face', 'VBP'), ('obstacles', 'NNS'), ('test', 'VBP'), ('resilience', 'NN'), ('.', '.')]\n",
      "[('It', 'PRP'), ('essential', 'JJ'), (',', ','), ('however', 'RB'), (',', ','), ('remember', 'VB'), ('every', 'DT'), ('step', 'NN'), ('forward', 'RB'), ('victory', 'NN'), (',', ','), ('challenge', 'NN'), (',', ','), ('grow', 'NN'), ('stronger', 'NN'), (',', ','), ('wiser', 'NN'), (',', ','), ('connected', 'VBN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowballstemmer = SnowballStemmer('english')\n",
    "for i in range(len(sentences)):\n",
    "    words_snowball = nltk.word_tokenize(sentences[i])\n",
    "    words_snowball = [word for word in words_snowball if word not in set(stopwords.words('english'))]\n",
    "    #sentences[i] = ' '.join(words_snowball)\n",
    "    #using pos tag for words\n",
    "    pos_tag = nltk.pos_tag(words_snowball)\n",
    "    print(pos_tag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Taj', 'NNP'), ('Mahal', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('monument', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "text = \"Taj Mahal is a beautiful monument\"\n",
    "postag_text = nltk.pos_tag(text.split())\n",
    "print(postag_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/kushal/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/kushal/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/kushal/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#Use NLTK's currently recommended named entity chunker to chunk the given list of tagged tokens.\n",
    "import nltk\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')  # Required for NE chunking\n",
    "nltk.download('averaged_perceptron_tagger')  # Required for POS tagging\n",
    "#make a graph with named entity recognition for pos tags.\n",
    "tag_elements = nltk.ne_chunk(postag_text).draw()\n",
    "print(tag_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
